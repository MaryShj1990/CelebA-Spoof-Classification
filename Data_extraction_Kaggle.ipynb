{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Import required libraries**","metadata":{}},{"cell_type":"code","source":"# Import libraries \nimport numpy as np  # Linear algebra\nimport os    # Library for interacting with operating system\nimport cv2   # Computer vision library","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:38:14.675890Z","iopub.execute_input":"2022-08-07T15:38:14.678217Z","iopub.status.idle":"2022-08-07T15:38:14.787629Z","shell.execute_reply.started":"2022-08-07T15:38:14.677737Z","shell.execute_reply":"2022-08-07T15:38:14.786196Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## **Define functions**\n* **standard_bbox_values()**\n  * **inputs:** bounding box path, the width and height of image\n  * **output:** standard values for the entries of bounding box (bbox[0], bbox[1], bbox[2], bbox[3])\n \n \n* **get_padding_bbox_elements()**\n  * **inputs:** bounding box entries: x1, y1, w1, h1, the width and height of image: real_w, real_h, ratio_bbox_and_image\n  * **output:** padded bounding box entries","metadata":{}},{"cell_type":"code","source":"#This function takes the elements of bounding box and returns their standard values based on README file provided with the dataset\ndef standard_bbox_values(bbox_path, real_w, real_h):\n    bbox_read = open(bbox_path, \"r\")       # Open the bounding box txt file as a file object\n    bbox = list(bbox_read)[0].split()      # Split the text by the whitespace separator and return bounding box elements in string type\n    \n    x1 = int(int(bbox[0]) * (float(real_w) / 224))  # bbox[0]\n    y1 = int(int(bbox[1]) * (float(real_h) / 224))  # bbox[1]\n    w1 = int(int(bbox[2]) * (float(real_w) / 224))  # bbox[2]\n    h1 = int(int(bbox[3]) * (float(real_h) / 224))  # bbox[3]\n    \n    return x1, y1, w1, h1\n\n#This function adds padding to the bounding box while ensuring it is inside the image\ndef get_padding_bbox_elements(x1, y1, w1, h1, real_w, real_h, ratio_bbox_and_image):\n    x1_padding = x1 - int((w1) * (1 + ratio_bbox_and_image))\n    y1_padding = y1 - int((h1) * (1 + ratio_bbox_and_image))\n    w1_padding = w1 + int((w1) * (1 + ratio_bbox_and_image))\n    h1_padding = h1 + int((h1) * (1 + ratio_bbox_and_image))\n    x1_padding = max(0, x1_padding) \n    y1_padding = max(0, y1_padding)\n    w1_padding = min(real_w, w1_padding)\n    h1_padding = min(real_h, h1_padding)\n        \n    return x1_padding, y1_padding, w1_padding, h1_padding","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:38:18.481081Z","iopub.execute_input":"2022-08-07T15:38:18.482146Z","iopub.status.idle":"2022-08-07T15:38:18.492922Z","shell.execute_reply.started":"2022-08-07T15:38:18.482099Z","shell.execute_reply":"2022-08-07T15:38:18.491639Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## **Extract the image samples - Part 1:**\n* Get the standard values of the face bounding box provided along with each image\n* Add padding to the bounding box\n* Crop the original image by the bounding box, resize it, and store it \n* Assign label '1' to *live* image and label '0' to *spoof* image and store it","metadata":{}},{"cell_type":"code","source":"import gc                         # garbage collector\n\nimg_face = []                    # extracted face images\nimg_label = []                   # labels (spoof:0, live:1) for extracted face images\nfolders = []\ncount_live = 0                   # live counter\ncount_spoof = 0                  # spoof counter\ncount_limit_live = 2        # number of extracted live samples\ncount_limit_spoof = 2       # number of extracted spoof samples\n\ntrain_path = '/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/Data/train'\nfor folder in os.listdir(train_path):       # a list of names of all the folders present in train_path (folders: 1, 10, 1000, ...)\n    folders.append(folder)                  # store the extracted folders \n    gc.collect()                          # release unreferenced memory\n\n    d = os.path.join(train_path, folder)    # concatenate train_path and folder\n    if os.path.isdir(d):\n        for e in os.listdir(d):\n            imgs_path = os.path.join(d, e)          # live or spoof folder path\n            for img_path in os.listdir(imgs_path):\n                if (img_path.endswith('.jpg')):     # if it is an image not bounding box txt file\n                    full_img_path = os.path.join(imgs_path, img_path)\n                    bound_box_path = full_img_path[0:-4] + '_BB.txt'    # bbox path and img path differ only in a few last words (their suffix)\n                    img = cv2.imread(full_img_path)                     # read the image\n                    real_w = img.shape[1]                               # image width\n                    real_h = img.shape[0]                               # image height\n                    x1, y1, w1, h1 = standard_bbox_values(bound_box_path, real_w, real_h)      # get the standard values for bounding box entries based on README file provided\n                    ratio_bbox_and_image = (w1 * h1) / (real_w * real_h)                       # the ratio of bbox area to img area\n                    x1_padding, y1_padding, w1_padding, h1_padding = get_padding_bbox_elements(x1, y1, w1, h1, \n                                                                                              real_w, real_h,\n                                                                                              ratio_bbox_and_image)   # add padding to the bounding box\n                    cropped_img = img[y1_padding:y1+h1_padding, x1_padding:x1+w1_padding]                             # crop the original image by the padded bounding box\n                    try:\n                        if (e == 'live' and count_live >= count_limit_live) or (e == 'spoof' and count_spoof >= count_limit_spoof):\n                            continue\n                        resized_cropped_img = cv2.resize(cropped_img, (224, 224), interpolation = cv2.INTER_AREA)      # resize the cropped face image to (224,224)\n                        img_face.append(resized_cropped_img)\n                        if e == 'live':\n                            count_live = count_live + 1\n                            img_label.append(1)                               # assign label '1' to live image\n                        elif e == 'spoof':\n                            count_spoof = count_spoof + 1\n                            img_label.append(0)                              # assign label '0' to spoof image\n                    except:\n                        continue\n\n                    if (count_live == count_limit_live and e == 'live') or (count_spoof == count_limit_spoof and e == 'spoof'):\n                        break\n            if count_live >= count_limit_live and count_spoof >= count_limit_spoof:\n                break\n    if count_live >= count_limit_live and count_spoof >= count_limit_spoof:\n        print(\"DONE Extracting \")\n        break\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:38:23.955197Z","iopub.execute_input":"2022-08-07T15:38:23.956030Z","iopub.status.idle":"2022-08-07T15:38:24.718086Z","shell.execute_reply.started":"2022-08-07T15:38:23.955985Z","shell.execute_reply":"2022-08-07T15:38:24.716674Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## **Save images and lables into one single NPZ file**","metadata":{}},{"cell_type":"code","source":"X = np.asarray(img_face)    # convert to numpy array\ny = np.asarray(img_label)\nnp.savez('anti_spoofing_data.npz', X, y)   # Save all the numpy arrays into one single npz file\nprint(\"DONE SAVING NPZ FILE\")","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:55:04.737790Z","iopub.execute_input":"2022-08-07T15:55:04.738223Z","iopub.status.idle":"2022-08-07T15:55:04.748996Z","shell.execute_reply.started":"2022-08-07T15:55:04.738189Z","shell.execute_reply":"2022-08-07T15:55:04.747222Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## **Download the NPZ file**","metadata":{}},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'anti_spoofing_data.npz')","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:38:51.124388Z","iopub.execute_input":"2022-08-07T15:38:51.124810Z","iopub.status.idle":"2022-08-07T15:38:51.135686Z","shell.execute_reply.started":"2022-08-07T15:38:51.124777Z","shell.execute_reply":"2022-08-07T15:38:51.134186Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"np.savez('folders.npz',folders) \nfrom IPython.display import FileLink\nFileLink(r'folders.npz')","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:39:34.599034Z","iopub.execute_input":"2022-08-07T15:39:34.599470Z","iopub.status.idle":"2022-08-07T15:39:34.607763Z","shell.execute_reply.started":"2022-08-07T15:39:34.599435Z","shell.execute_reply":"2022-08-07T15:39:34.606644Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## **Extract the image samples - Part 2**\nDue to the limitations of kaggle resources, I extracted 80k number of images in two parts: 40k in part 1, and 40k in part 2. Therefore, the below codes are the same as above.","metadata":{}},{"cell_type":"code","source":"folders = np.load('../input/foldernamepart1/folders.npz')   # load the folders extracted in part 1","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:48:36.511411Z","iopub.execute_input":"2022-08-07T15:48:36.512025Z","iopub.status.idle":"2022-08-07T15:48:36.530314Z","shell.execute_reply.started":"2022-08-07T15:48:36.511975Z","shell.execute_reply":"2022-08-07T15:48:36.529292Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import gc\n\nimg_face = []     # Extracted face images\nimg_label = []    # Labels (spoof:0, live:1) for extracted face images\nfolders_part2 = []\ncount_live = 0                   # live counter\ncount_spoof = 0                  # spoof counter\ncount_limit_live = 20000        # Number of extracted live samples\ncount_limit_spoof = 20000       # Number of extracted spoof samples\n\ntrain_path = '/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/Data/train'\nfor folder in os.listdir(train_path):   # a list of names of all the folders present in train_path (folders: 1, 10, 1000, ...)\n    if folder not in folders:           # if this folder has not already been extracted in part 1\n        folders_part2.append(folder)    # store the extracted folders \n        gc.collect()                  # release unreferenced memory\n\n        d = os.path.join(train_path, folder)                                  # concatenate train_path and folder\n        if os.path.isdir(d):\n            for e in os.listdir(d): \n                imgs_path = os.path.join(d, e)                                # live or spoof folder path \n                for img_path in os.listdir(imgs_path):\n                    if (img_path.endswith(\".jpg\")):                           # if it is an image not bounding box txt file\n                        full_img_path = os.path.join(imgs_path, img_path)\n                        bound_box_path = full_img_path[0:-4] + '_BB.txt'      # bbox path and img path differ only in a few last words (their suffix)\n                        img = cv2.imread(full_img_path)                       # read the image\n                        real_w = img.shape[1]                                 # image width\n                        real_h = img.shape[0]                                 # image height\n                        x1, y1, w1, h1 = standard_bbox_values(bound_box_path, real_w, real_h)      # get the standard values for bounding box entries based on README file provided\n                        ratio_bbox_and_image = (w1 * h1) / (real_w * real_h)                       # the ratio of bbox area to img area\n                        x1_padding, y1_padding, w1_padding, h1_padding = get_padding_bbox_elements(x1, y1, w1, h1, \n                                                                                                  real_w, real_h,\n                                                                                                  ratio_bbox_and_image)    # add padding to the bounding box\n                        cropped_img = img[y1_padding:y1+h1_padding, x1_padding:x1+w1_padding]                              # crop the original image by the padded bounding box\n                        try:\n                            if (e == 'live' and count_live >= count_limit_live) or (e == 'spoof' and count_spoof >= count_limit_spoof):\n                                continue\n                            resized_cropped_img = cv2.resize(cropped_img, (224, 224), interpolation = cv2.INTER_AREA)      # resize the cropped face image to (224,224)\n                            img_face.append(resized_cropped_img)\n                            if e == 'live':\n                                count_live = count_live + 1\n                                img_label.append(1)                                # assign label '1' to live image\n                            elif e == 'spoof':\n                                count_spoof = count_spoof + 1\n                                img_label.append(0)                                # assign label '0' to spoof image\n                        except:\n                            continue\n\n                        if (count_live == count_limit_live and e == 'live') or (count_spoof == count_limit_spoof and e == 'spoof'):\n                            break\n                if count_live >= count_limit_live and count_spoof >= count_limit_spoof:\n                    break\n        if count_live >= count_limit_live and count_spoof >= count_limit_spoof:\n            print(\"DONE Extracting \")\n            break\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T01:40:12.777067Z","iopub.execute_input":"2022-08-07T01:40:12.777456Z","iopub.status.idle":"2022-08-07T01:40:12.937135Z","shell.execute_reply.started":"2022-08-07T01:40:12.777427Z","shell.execute_reply":"2022-08-07T01:40:12.935994Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X = np.asarray(img_face)    # convert to numpy array\ny = np.asarray(img_label)\nnp.savez('anti_spoofing_data_part2.npz', X, y)   # Save all the numpy arrays into one single npz file\nprint(\"DONE SAVING NPZ FILE\")","metadata":{"execution":{"iopub.status.busy":"2022-07-17T18:09:13.601479Z","iopub.execute_input":"2022-07-17T18:09:13.601995Z","iopub.status.idle":"2022-07-17T18:09:13.687784Z","shell.execute_reply.started":"2022-07-17T18:09:13.601877Z","shell.execute_reply":"2022-07-17T18:09:13.686271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'anti_spoofing_data_part2.npz')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T19:52:13.498777Z","iopub.execute_input":"2022-07-08T19:52:13.499108Z","iopub.status.idle":"2022-07-08T19:52:13.507687Z","shell.execute_reply.started":"2022-07-08T19:52:13.499081Z","shell.execute_reply":"2022-07-08T19:52:13.506692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.savez('folders_part2.npz',folders_part2) \nfrom IPython.display import FileLink\nFileLink(r'folders_part2.npz')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T19:53:12.532079Z","iopub.execute_input":"2022-07-08T19:53:12.532399Z","iopub.status.idle":"2022-07-08T19:53:12.544906Z","shell.execute_reply.started":"2022-07-08T19:53:12.532369Z","shell.execute_reply":"2022-07-08T19:53:12.543876Z"},"trusted":true},"execution_count":null,"outputs":[]}]}