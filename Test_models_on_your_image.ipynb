{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **import libraries**"
      ],
      "metadata": {
        "id": "K-AsqYL20FhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from google.colab.patches import cv2_imshow # for image display\n",
        "import random\n",
        "random.seed(0)\n",
        "import tensorflow as tf\n",
        "np.random.seed(0)\n",
        "tensorflow.random.set_seed(0)"
      ],
      "metadata": {
        "id": "XEZ8vdR10Gil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzQC7ts5rfiy"
      },
      "source": [
        "#**mount google drive** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QF0b01xrxw3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import the desired model from Google Drive**"
      ],
      "metadata": {
        "id": "vE_UwQV50g2G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWQkWWFyr47x"
      },
      "outputs": [],
      "source": [
        "!cp  /content/drive/MyDrive/Face_Anti_Spoofing_Dataset/hybrid_model_d5_final.h5 /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **load the model**"
      ],
      "metadata": {
        "id": "GqKu2xo70l0d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivuDzQ5gsaIX"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# returns a compiled model\n",
        "hybrid_model = load_model('/content/hybrid_model_d5_final.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import your image samples to be classified by the model**"
      ],
      "metadata": {
        "id": "7Q74fpLw1vVd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgltzpRIYR4u"
      },
      "outputs": [],
      "source": [
        "!cp  /content/drive/MyDrive/Face_Anti_Spoofing_Dataset/2_real.jpg /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import XML file containing Haar cascade detector of faces**"
      ],
      "metadata": {
        "id": "KLXM5CRT6lBW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rCxGuoafX7i"
      },
      "outputs": [],
      "source": [
        "!cp  /content/drive/MyDrive/Face_Anti_Spoofing_Dataset/haarcascade_frontalface_default.xml /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVI4_0A2d7k5"
      },
      "source": [
        "# **test the model on the real-world samples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh51FxkyevkC"
      },
      "outputs": [],
      "source": [
        "from cv2 import CascadeClassifier\n",
        "from cv2 import rectangle\n",
        "faceCascade=CascadeClassifier('/content/haarcascade_frontalface_default.xml')\n",
        "from google.colab.patches import cv2_imshow\n",
        "from cv2 import waitKey\n",
        "from cv2 import destroyAllWindows\n",
        "\n",
        "image_size = (224, 224)\n",
        "\n",
        "img_path = '/content/2_real.jpg'\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "# create transparent overlay for bounding box\n",
        "bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "bboxes = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "# print bounding box for each detected face\n",
        "for box in bboxes:\n",
        "  # extract\n",
        "  x, y, width, height = box\n",
        "  x2, y2 = x + width, y + height\n",
        "      \n",
        "x = x\n",
        "y = y\n",
        "w = width\n",
        "h = height\n",
        "    \n",
        "image=cv2.resize(img,(image_size))\n",
        "image2=image.reshape(1,224,224,3)\n",
        "detection_result=hybrid_model.predict([image2,image2])\n",
        "if (detection_result[0][0]>0.5):\n",
        "  img = cv2.rectangle(img,(x,y),(x+w,y+h),(36,255,12),2)\n",
        "  img=cv2.putText(img, 'Live', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "      \n",
        "else:\n",
        "  img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "  img=cv2.putText(img, 'Spoof', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)\n",
        "\n",
        "\n",
        "# show the image\n",
        "cv2_imshow( img)\n",
        "\n",
        "waitKey(0)\n",
        "# close the window\n",
        "destroyAllWindows()     "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}